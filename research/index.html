<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Home - CATS @ U of Arizona</title>
  <meta name="description" content="CATS Group at University of Arizona CEAM">
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="/">
  <link rel="shortcut icon" type ="image/x-icon" href="/favicon.ico">
  <!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css"> -->
  <!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/fontawesome.min.css"> -->
  <!-- <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css" rel="stylesheet"> -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
  <!-- <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">


  <link rel="preconnect" href="https://player.vimeo.com">
  <link rel="preconnect" href="https://i.vimeocdn.com">
  <link rel="preconnect" href="https://f.vimeocdn.com">



<!-- Google Analytics (original) -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-167467135-1', 'auto');
  ga('send', 'pageview');

</script>

<!-- Global site tag (gtag.js) - Google Analytics 4 -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-BKG8WP924R"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-BKG8WP924R');
</script>

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5KBZDTG');</script>
<!-- End Google Tag Manager -->



<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Home | CATS @ U of Arizona</title>  
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="Home" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="CATS Group at University of Arizona CAEM" />
<meta property="og:description" content="CATS Group at University of Arizona CAEM" />
<link rel="canonical" href="/" />
<meta property="og:url" content="/" />
<meta property="og:site_name" content="Civil Eng. @ UA CAEM" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Home" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"CATS Group at University of Arizona CAEM","headline":"Home","name":"Civil Eng. @ UA CAEM","url":"/"}</script>
<!-- End Jekyll SEO tag -->



</head>


  <body>

    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5KBZDTG"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<nav class="navbar sticky-top navbar-expand-md navbar-dark bg-dark justify-content-center">
    <div class="container-fluid">
    <a class="navbar-brand" href="/">
        <img src="/favicon.ico" width="30" height="30" style="margin-right:5px" class="d-inline-block align-top" alt="">
        Civil Eng. @ UA CAEM
    </a>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto">
            <li class="nav-item dropdown">
                <li class="nav-item">
                  <a class="nav-link" href="/">Home</a>
                </li> 
                
                    <li class="nav-item">
                        <a class="nav-link" href="/team">Team</a>
                    </li> 
                
                    <li class="nav-item">
                        <a class="nav-link" href="/papers">Papers</a>
                    </li> 
                
                    <li class="nav-item">
                        <a class="nav-link" href="/research">Research</a>
                    </li> 
                
                    <li class="nav-item">
                        <a class="nav-link" href="/teaching">Teaching</a>
                    </li> 
                
                    <li class="nav-item">
                        <a class="nav-link" href="/software">Software</a>
                    </li> 
                
                    <li class="nav-item">
                        <a class="nav-link" href="/hardware">Hardware</a>
                    </li> 
                
                <!-- <a class="nav-link" href="/GSCS22">GSCS22</a> -->
            </li>
        </ul>
    </div>
    </div>
</nav>


    <div class="container-fluid">
      <div class="row">
        <div id="gridid" class="col-sm-12 col-xs-12">
  <h2 id="research">Research</h2>

<style>
img{
  border-radius: 10px;
}
.col-md-3 {
  margin-top:10px;
  margin-bottom:10px;
  padding:0px;
  display:block;
  overflow:hidden;
  text-align:center;
  display: table-cell;
  background: white;
  border-radius: 20px;
  height: auto;
  <!-- border: 1px solid black; -->
}
iframe {
  margin:0;
  padding:0;
  width: 175px;
  display: inline;
  vertical-align: middle;
}
</style>

<!-- <p><strong>Note:</strong> This page is always a bit out of date. Our research interests can be gleaned via <a href="/papers" target="_blank">our papers</a> and the <a href="/" target="_blank">home page</a>.</p> -->

<div class="jumbotron">
  <h4>Traffic Anomaly Detection</h4>
  <p align="justify">In this project, we developed a framework for detecting traffic anomalies in video data. The proposed methodology relies on an augmented annotation pipeline that pre-annotates the training
dataset using an object detection model trained on the COCO dataset. Annotations are subsequently used to build a vehicle detection model using the YOLOv5 network. Next, we estimate the background of each traffic video by computing the median
of frames randomly sampled from a uniform distribution over a thirty-second period. Vehicle detections on extracted backgrounds are classified as anomaly candidates. Factors such as vehicle detection size, likelihood, and road feature masks were
used to construct a decision tree to eliminate false anomalies. The start and end of an anomaly were computed by superimposing detections from anomaly candidates and their foreground detections. The main contributions are as follows</p>
  <div class="row align-items-end">
    <div class="col-md-9 col-sm-12">
      <ul>
        <li> Developed a fast and efficient data annotation pipeline</li>
        <li> Developed decision-tree based method for anomaly detection</li>
        <li> Developed a real-time model for traffic anomaly detections</li>
      </ul>
    </div>
    <div class="col-md-3 col-sm-12" style="background-color:transparent">
      <p><img width="100%" src="/images/aboah/anomaly.jpg" /></p>
    </div>
  </div>
</div>

<div class="jumbotron">
  <div class="row align-items-end">
    <div class="col-md-9 col-sm-12">
      <h4>Traffic Signal Performance Evaluation for Vulnerable Road Users </h4>
      <p align="justify">This project has 2 main
objectives: 1) to categorize pedestrians into subcategories in order to address their safety requirements at intersections; 2) to
estimate the time required to cross an intersection and determine whether the pedestrian can safely cross within the pedestrian signal time allotted at intersections. The objectives were accomplished using data collected from three Ouster digital LiDAR sensors installed at an intersection in Chattanooga, Tennessee. The data was collected over a period of 3 hours. The datasets contain pedestrian and signal phase data. The LiDAR dataset included information about the physical characteristics
of pedestrians such as their speeds, positions, directions, and size. The study defined heuristics to subclassify the pedestrian
and evaluated the accuracy of the sub-classification using machine learning models. The study also carried analysis to determine 
	      if pedestrians were able to cross the intersection or not during the pedestrian allocated time</p>
    </div>
    <div class="col-md-3 col-sm-12" style="background-color:transparent;">
      <iframe src="https://player.vimeo.com/video/455888052?autoplay=1&amp;loop=1&amp;autopause=0&amp;muted=1&amp;quality=240p&amp;background=1" height="182px" frameborder="0" allow="autoplay"></iframe>
    </div>
  </div>
</div>

<p><!-- <iframe src="https://player.vimeo.com/video/455887852?autoplay=1&loop=1&autopause=0&muted=1&quality=240p&background=1" height="142px" frameborder="0" allow="autoplay"></iframe> --></p>

<div class="jumbotron">
  <div class="row align-items-end">
    <div class="col-md-9 col-sm-12">
      <h4>DeepSegmenter: Temporal Action Localization for Detecting Anomalies in Untrimmed Naturalistic Driving Videos</h4>
      <p>Identifying unusual driving behaviors exhibited by drivers during driving is essential for understanding driver
behavior and the underlying causes of crashes. Previous studies have primarily approached this problem as a classification task, assuming that naturalistic driving videos come
discretized. However, both activity segmentation and classification are required for this task due to the continuous nature of naturalistic driving videos. The current study therefore departs from conventional approaches and introduces
a novel methodological framework, DeepSegmenter, that simultaneously performs activity segmentation and classification in a single framework. The proposed framework
consists of four major modules namely Data Module, Activity Segmentation Module, Classification Module and Postprocessing Module. Our proposed method won 8th place
in the 2023 AI City Challenge, Track 3, with an activity overlap score of 0.5426 on experimental validation data. The experimental results demonstrate the effectiveness, efficiency, and robustness of the proposed system.</p>
    </div>
    <div class="col-md-3 col-sm-12">
      <iframe src="https://player.vimeo.com/video/455688521?autoplay=1&amp;loop=1&amp;autopause=0&amp;muted=1&amp;quality=240p&amp;background=1" height="192px" frameborder="0" allow="autoplay"></iframe>
    </div>
  </div>
</div>

<div class="jumbotron">
  <div class="row align-items-end">
    <div class="col-md-9 col-sm-12">
      <h4>Real-time Multi-Class Helmet Violation Detection Using Few-Shot Data Sampling Technique and YOLOv8</h4>
      <p>Traffic safety is a major global concern. Helmet usage is a key factor in preventing head injuries and fatalities caused by motorcycle accidents. However, helmet usage violations continue to be a significant problem. To
identify such violations, automatic helmet detection systems have been proposed and implemented using computer vision techniques. Real-time implementation of such systems is crucial for traffic surveillance and enforcement, however, most of these systems are not real-time. This study proposes a robust real-time helmet violation detection system. The proposed system utilizes a unique data
processing strategy, referred to as few-shot data sampling, to develop a robust model with fewer annotations, and a single-stage object detection model, YOLOv8 (You Only
Look Once Version 8), for detecting helmet violations in real-time from video frames. Our proposed method won 7th place in the 2023 AI City Challenge, Track 5, with
an mAP score of 0.5861 on experimental validation data. The experimental results demonstrate the effectiveness, efficiency, and robustness of the proposed system.</p>
    </div>
    <div class="col-md-3 col-sm-12" style="background-color:transparent">
      <p><img src="/images/respic/lithotripsy.jpg" width="175px" /></p>
    </div>
  </div>
</div>

<div class="jumbotron">
  <div class="row align-items-end">
    <div class="col-md-9 col-sm-12">
      <h4>An <em>in silico</em> Driver Maneuver Detection</h4>
      <p>The current paper implements a methodology for automatically detecting vehicle maneuvers from vehicle telemetry data under naturalistic driving settings. Previous approaches have treated vehicle maneuver detection as a classification problem, although both time series segmentation
and classification are required since input telemetry data is continuous. Our objective is to develop an end-to-end
pipeline for frame-by-frame annotation of naturalistic driving studies videos into various driving events including stop and lane keeping events, lane changes, left-right turning
movements, and horizontal curve maneuvers. To address the time series segmentation problem, the study developed
an Energy Maximization Algorithm (EMA) capable of extracting driving events of varying durations and frequencies from continuous signal data. To reduce overfitting and
false alarm rates, heuristic algorithms were used to classify events with highly variable patterns such as stops and lanekeeping. To classify segmented driving events, four machine
learning models were implemented, and their accuracy and transferability were assessed over multiple data sources. The duration of events extracted by EMA were comparable to actual events, with accuracies ranging from 59.30%
(left lane change) to 85.60% (lane-keeping). Additionally, the overall accuracy of the 1D-convolutional neural network model was 98.99%, followed by the Long-short-termmemory model at 97.75%, then random forest model at
97.71%, and the support vector machine model at 97.65%. These model accuracies where consistent across different data sources. The study concludes that implementing a
segmentation-classification pipeline significantly improves both the accuracy for driver maneuver detection and transferability of shallow and deep ML models across diverse
datasets.</p>

    </div>
    <div class="col-md-3 col-sm-12">
      <iframe src="https://player.vimeo.com/video/455887647?autoplay=1&amp;loop=1&amp;autopause=0&amp;muted=1&amp;quality=240p&amp;background=1" frameborder="0" allow="autoplay"></iframe>
    </div>
  </div>
</div>

<p><!-- <iframe src="https://player.vimeo.com/video/455887646?autoplay=1&loop=1&autopause=0&muted=1&quality=240p&background=1" frameborder="0" allow="autoplay"></iframe> -->
<!-- <div class="embed-container embed-container-spleen"> -->
<!-- </div> --></p>

<!-- <div class="embed-container embed-container-leuk"> -->
<!--   <iframe src="https://player.vimeo.com/video/455887647?autoplay=1&loop=1&autopause=0&muted=1&quality=240p&background=1" frameborder="0" allow="autoplay"></iframe> -->
<!-- </div> -->

<div class="jumbotron">
  <div class="row align-items-end">
    <div class="col-md-9 col-sm-12">
      <h4>Pavement Roughness Estimation</h4>
      <p>The primary objective of this project was to develop a model to quickly and accurately determine the IRI values of road sections at a cheaper cost. 
	      In this project, I developed a smartphone app to collect road surface data at a cheaper cost. Also, I utilized other variables such as speed and 
	      gyroscope information in addition to the vertical acceleration information to increase the accuracy of determining IRI values of road sections</p>
    </div>
    <div class="col-md-3 col-sm-12">
      <iframe src="https://player.vimeo.com/video/455887720?autoplay=1&amp;loop=1&amp;autopause=0&amp;muted=1&amp;quality=240p&amp;background=1" height="156px" frameborder="0" allow="autoplay"></iframe>
    </div>
  </div>
</div>


</div>

      </div>
    </div>

    <br/>
<section id="footer">
<div class="container-footer">
  <div class="panel-footer">
	  <div class="row">
		<div class="col-sm-3">
		    <h5>About</h5>	
            <p><a href="https://caem.engineering.arizona.edu/" target="_blank">Department of Civil Eng.</a><br/> <a href="https://www.engr.arizona.edu/index" target="_blank">College of Engineeering</a><br/> U of Arizona
</p>
		</div>

		<div class="col-sm-3">
		    <h5>Information</h5>	
            <p><a href="mailto:aboah1994@gmail.com" target="_blank"><i class="fa fa-envelope fa-1x"></i> Email Aboah</a> <br/> <a href="/vacancies.html"><i class="fa fa-users fa-1x"></i> Explore openings</a> <br/> <a href="https://github.com/sbryngelson/academic-website-template"><i class="fab fa-github fa-1x"></i> Site template</a> 
</p>
		</div>

		<div class="col-sm-6">
<!-- <h5>Coordinates</h5> -->	
            <p><br/> <img src='/images/aboah/logo1.jpg' width=90% title='This logo was designed by Armstrong!'>
</p>
		</div>
	  </div>

      <center><p>Last updated on Jul 10, 2023</br>
      &copy 2019-2023 CATS @ UA </p></center>
	</div>
  </div>
</div>

<script src="/assets/javascript/bootstrap/jquery.min.js"></script>
<!-- <script src="/assets/javascript/popper/dist/umd/popper.min.js"></script> -->
<script src="/assets/javascript/bootstrap/bootstrap.bundle.min.js"></script>
<!-- <script src="/assets/javascript/shb.js"></script> -->



  </body>

</html>
